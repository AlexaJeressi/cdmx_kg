{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c1f6f5",
   "metadata": {},
   "source": [
    "# Connect to Chatgpt API to collect entities and relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b83dfc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()  # loads variables from .env\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5415a321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are five random fruits:\n",
      "\n",
      "1. Mango\n",
      "2. Kiwi\n",
      "3. Dragon fruit\n",
      "4. Blueberry\n",
      "5. Papaya\n"
     ]
    }
   ],
   "source": [
    "# Quick test: Ask model for 5 words\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say 5 random fruits\"}],\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b789a92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              row_id  doc_hash                                 document_name  \\\n",
      "0  F823AF8C_ARTCULO1  F823AF8C  CONSTITUCIÓN POLÍTICA DE LA CIUDAD DE MÉXICO   \n",
      "1  F823AF8C_ARTCULO2  F823AF8C  CONSTITUCIÓN POLÍTICA DE LA CIUDAD DE MÉXICO   \n",
      "2  F823AF8C_ARTCULO3  F823AF8C  CONSTITUCIÓN POLÍTICA DE LA CIUDAD DE MÉXICO   \n",
      "3  F823AF8C_ARTCULO4  F823AF8C  CONSTITUCIÓN POLÍTICA DE LA CIUDAD DE MÉXICO   \n",
      "4  F823AF8C_ARTCULO5  F823AF8C  CONSTITUCIÓN POLÍTICA DE LA CIUDAD DE MÉXICO   \n",
      "\n",
      "  document_section_title                                               text  \n",
      "0             Artículo 1  De la Ciudad de México\\n\\n1. \\tLa Ciudad de Mé...  \n",
      "1             Artículo 2  De la naturaleza intercultural, pluriétnica, p...  \n",
      "2             Artículo 3  De los principios rectores\\n\\n1. \\tLa dignidad...  \n",
      "3             Artículo 4  Principios de interpretación y aplicación de l...  \n",
      "4             Artículo 5  Ciudad garantista\\n\\nA. Progresividad de los d...  \n"
     ]
    }
   ],
   "source": [
    "# Load your Excel file\n",
    "df = pd.read_excel(\"/Users/alexa/Projects/cdmx_kg/Mexico_City/test_01.xlsx\")\n",
    "df = df[['row_id','doc_hash','document_name', 'document_section_title', 'text']]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b193abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Firstly ask to identify entities. \n",
    "# Output is a csv with a art_name | mention | \n",
    "\n",
    "# Prompts\n",
    "def prompt_entities(batch):\n",
    "    text = \"\\n\\n\".join(\n",
    "        f\"ROW_ID: {row.row_id}\\n\"\n",
    "        f\"DOCUMENT: {row.document_name}\\n\"\n",
    "        f\"SECTION: {row.document_section_title}\\n\"\n",
    "        f\"TEXT: {row.text}\"\n",
    "        for row in batch.itertuples()\n",
    "    )\n",
    "    return f\"\"\"\n",
    "You are a specialized legal entity extraction system for Mexico City government documents. \n",
    "Your task is to be EXHAUSTIVE and find ALL government entities mentioned.\n",
    "\n",
    "CRITICAL: \n",
    "- READ EVERY WORD CAREFULLY. Do not miss any government entity, no matter how briefly mentioned.\n",
    "- DO NOT INCLUDE LAW MENTIONS. ONLY GOVERNMENT ENTITIES.\n",
    "\n",
    "TASK: Extract ALL government entities, institutions, and legal bodies from these legal texts.\n",
    "\n",
    "ENTITY TYPES TO IDENTIFY (scan for ALL of these):\n",
    "- Secretarías (ministries): Secretaría de..., SEDEMA, SEDUVI, SIBISO, STyFE, etc.\n",
    "- Alcaldías (municipal governments): Alcaldía..., any of the 16 alcaldías\n",
    "- Institutos and agencies: Instituto de..., Agencia de..., ADIP, etc.\n",
    "- Tribunales and courts: Tribunal..., Juzgado..., Corte..., etc.\n",
    "- Consejos and commissions: Consejo de..., Comisión de..., etc.\n",
    "- Universities and schools: Universidad de..., UACM, etc.\n",
    "- Procuradurías: Procuraduría..., PAOT, etc.\n",
    "- Federal entities: SEMARNAT, CONAGUA, PROFEPA, etc.\n",
    "- Any organization with official government role\n",
    "\n",
    "COMPREHENSIVE EXTRACTION RULES:\n",
    "1. Extract EXACTLY as written in the text (preserve case, accents, articles like \"la\", \"el\")\n",
    "2. Include full official names AND abbreviations when mentioned\n",
    "3. Look for entities in ALL parts of the text, including parentheses, footnotes, lists\n",
    "4. Capture entities mentioned in different forms (e.g., \"la Secretaría\", \"dicha Secretaría\")\n",
    "5. Include entities that appear in compound phrases\n",
    "6. Do NOT skip vague references - if it's a government body, include it\n",
    "7. Be especially careful with lists and enumerated items\n",
    "\n",
    "SEARCH STRATEGY:\n",
    "- Read the text word by word\n",
    "- Look for capital letters that might indicate proper nouns\n",
    "- Check for organizational keywords: Secretaría, Instituto, Consejo, Comisión, Alcaldía, etc.\n",
    "- Examine abbreviations in parentheses\n",
    "- Review any lists or bullet points carefully\n",
    "\n",
    "OUTPUT FORMAT - CSV rows only, no headers, no markdown blocks:\n",
    "row_id,mention\n",
    "\n",
    "EXAMPLES:\n",
    "12406E12_ARTCULO5,Secretaría del Medio Ambiente\n",
    "12406E12_ARTCULO5,SEDEMA\n",
    "12406E12_ARTCULO5,Jefatura de Gobierno de la Ciudad de México\n",
    "12406E12_ARTCULO5,la Secretaría\n",
    "12406E12_ARTCULO5,Alcaldía Benito Juárez\n",
    "\n",
    "INPUT:\n",
    "{text}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "344e21e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Secondly ask to identify article mentions. \n",
    "#Each article mention must include the number article and the law.\n",
    "# Output is a csv with art_name | art_mention \n",
    "\n",
    "def prompt_article_mentions(batch):\n",
    "    text = \"\\n\\n\".join(\n",
    "        f\"ROW_ID: {row.row_id}\\n\"\n",
    "        f\"DOCUMENT: {row.document_name}\\n\"\n",
    "        f\"SECTION: {row.document_section_title}\\n\"\n",
    "        f\"TEXT: {row.text}\"\n",
    "        for row in batch.itertuples()\n",
    "    )\n",
    "    return f\"\"\"You are a specialized legal citation extraction system for Mexican law documents. Your mission is to find EVERY SINGLE legal reference, no matter how subtle.\n",
    "\n",
    "CRITICAL: SCAN EVERY WORD. Legal documents often have multiple references per sentence. Miss nothing.\n",
    "\n",
    "TASK: Find ALL references to articles, laws, codes, and legal documents from the TEXT content only.\n",
    "\n",
    "IMPORTANT: Only analyze the 'TEXT' field. The article name (SECTION) is just for identification purposes - it tells you which article the mentions were found in.\n",
    "\n",
    "STRICT EXTRACTION RULE - EXPLICIT MENTIONS ONLY:\n",
    "- ONLY extract laws, codes, and documents that are EXPLICITLY NAMED in the TEXT\n",
    "- Include COMPLETE law names - never truncate or abbreviate (e.g., \"LEY DEL DERECHO AL ACCESO, DISPOSICIÓN Y SANEAMIENTO DEL AGUA DE LA CIUDAD DE MÉXICO\")\n",
    "- DO NOT infer or assume law names that are not written in the text\n",
    "- DO NOT extract references to laws that are only implied or suggested\n",
    "\n",
    "CRITICAL - WHEN TO USE CURRENT LAW (from DOCUMENT field):\n",
    "- ONLY use current law for: \"esta Ley\", \"la presente Ley\", \"este Reglamento\", \"este Código\"\n",
    "- ONLY use current law for: standalone article numbers (e.g., \"artículo 5\" with NO law mentioned)\n",
    "- ONLY use current law for: relative references (\"artículo anterior\", \"artículo siguiente\")\n",
    "\n",
    "CRITICAL - WHEN NOT TO USE CURRENT LAW:\n",
    "- DO NOT use current law for entity mentions like \"la Secretaría\", \"las autoridades\"\n",
    "- DO NOT use current law for general legal concepts like \"normatividad\", \"disposiciones\"\n",
    "- IF NO EXPLICIT LAW NAME AND NOT IN ALLOWED EXCEPTIONS ABOVE → DO NOT EXTRACT\n",
    "\n",
    "\n",
    "CITATION TYPES TO EXTRACT (find ALL occurrences):\n",
    "- Article references: \"artículo 123\", \"art. 45\", \"artículos 1 al 15\", \"arts.\", \"apartado\"\n",
    "- Law references: \"Ley General de...\", \"Ley Ambiental\", \"Ley de...\", \"dicha Ley\", etc.\n",
    "- Self-references: \"esta Ley\", \"la presente Ley\", \"este Reglamento\", \"esta norma\"\n",
    "- Code references: \"Código Civil\", \"Código Penal\", \"códigos\"\n",
    "- Constitutional references: \"Constitución Política\", \"constitucional\", \"Carta Magna\"\n",
    "- Regulation references: \"Reglamento de...\", \"reglamentario\", \"normas reglamentarias\"\n",
    "- Decree references: \"Decreto\", \"decreto ejecutivo\"\n",
    "- Treaties and conventions: \"Tratado\", \"Convención\", \"acuerdo internacional\"\n",
    "- Relative references: \"artículo anterior\", \"artículo siguiente\", \"apartado anterior\"\n",
    "\n",
    "EXHAUSTIVE EXTRACTION RULES:\n",
    "1. ONLY extract mentions from the TEXT field, ignore SECTION and DOCUMENT fields\n",
    "2. For \"esta Ley\", \"la presente Ley\" → replace with actual current law name from DOCUMENT field\n",
    "3. For \"reglamento de esta Ley\", \"reglamento de la presente Ley\" → construct as \"REGLAMENTO DE LA [CURRENT LAW NAME]\"\n",
    "4. Extract complete citations as they appear in the text\n",
    "5. For article + law mentions: Include both article number AND the law/document it refers to\n",
    "6. For law-only mentions: If no article number is specified, leave art_num empty but include the law name\n",
    "7. Create ONE ROW per mention found - if one article contains multiple mentions, create multiple rows\n",
    "8. For article ranges (e.g., \"artículos 13 y 16\"), create separate rows for each article\n",
    "9. Check for references using pronouns (\"la misma\", \"dicha ley\", \"tal disposición\")\n",
    "10. In mention_extraction: Include the COMPLETE TEXT of the specific mention (the full phrase that mentions the article+law or law)\n",
    "11. Preserve original formatting and punctuation\n",
    "12. Law names can be very long with commas - extract them in full exactly as written\n",
    "\n",
    "\n",
    "SPECIAL HANDLING FOR RELATIVE REFERENCES:\n",
    "13. For \"artículo anterior\": Extract current article number from SECTION field, subtract 1, use current law from DOCUMENT field\n",
    "14. For \"artículo siguiente\": Extract current article number from SECTION field, add 1, use current law from DOCUMENT field\n",
    "15. For \"apartado anterior\", \"fracción anterior\": Only cite the current law name without any article number.\n",
    "16. Always verify the relative reference makes sense (don't create negative article numbers)\n",
    "\n",
    "SYSTEMATIC SEARCH APPROACH:\n",
    "- Read sentence by sentence\n",
    "- Look for legal keywords: artículo, ley, código, reglamento, decreto, etc.\n",
    "- Check numbers that might be article references\n",
    "- Search for relative terms: anterior, siguiente, precedente, subsecuente\n",
    "\n",
    "OUTPUT FORMAT - CSV rows only, no headers, no markdown blocks:\n",
    "row_id,art_num,law_name,mention_extraction\n",
    "\n",
    "Where:\n",
    "- row_id: Current article being analyzed (from ROW_ID field)\n",
    "- art_num: Article number being referenced (from TEXT field) - LEAVE EMPTY if no article number mentioned\n",
    "- law_name: COMPLETE law/document name containing the referenced article (NEVER truncate - use full name exactly as written)\n",
    "- mention_extraction: The COMPLETE TEXT of the specific mention\n",
    "\n",
    "EXAMPLES:\n",
    "For text: \"la presente Ley es reglamentaria de las disposiciones contenidas en el Apartado A del artículo 13 y del Apartado A del artículo 16 de la Constitución Política de la Ciudad de México\"\n",
    "Should produce TWO rows:\n",
    "12406E12_ARTCULO1,13,CONSTITUCIÓN POLÍTICA DE LA CIUDAD DE MÉXICO,artículo 13 de la Constitución Política de la Ciudad de México\n",
    "12406E12_ARTCULO1,16,CONSTITUCIÓN POLÍTICA DE LA CIUDAD DE MÉXICO,artículo 16 de la Constitución Política de la Ciudad de México\n",
    "\n",
    "For text: \"Se aplicará supletoriamente el Código Civil para el Distrito Federal en materia común\"\n",
    "Should produce ONE row:\n",
    "12406E12_ARTCULO3,,CÓDIGO CIVIL PARA EL DISTRITO FEDERAL,el Código Civil para el Distrito Federal\n",
    "\n",
    "For text: \"los demás que establezca el reglamento de la presente Ley\" (where current law is LEY AMBIENTAL DE LA CIUDAD DE MÉXICO)\n",
    "Should produce ONE row:\n",
    "12406E12_ARTCULO5,,REGLAMENTO DE LA LEY AMBIENTAL DE LA CIUDAD DE MÉXICO,el reglamento de la presente Ley\n",
    "\n",
    "For text: \"conforme a lo dispuesto en el artículo anterior\" (in ARTÍCULO 5 of LEY AMBIENTAL DE LA CIUDAD DE MÉXICO)\n",
    "Should produce ONE row:\n",
    "12406E12_ARTCULO5,4,LEY AMBIENTAL DE LA CIUDAD DE MÉXICO,el artículo anterior\n",
    "\n",
    "ALLOWED - USE CURRENT LAW:\n",
    "For text: \"esta Ley establece\" → 12406E12_ARTCULO5,,LEY AMBIENTAL DE LA CIUDAD DE MÉXICO,esta Ley\n",
    "For text: \"artículo 10\" (standalone number) → 12406E12_ARTCULO5,10,LEY AMBIENTAL DE LA CIUDAD DE MÉXICO,artículo 10\n",
    "For text: \"artículo anterior\" → 12406E12_ARTCULO5,4,LEY AMBIENTAL DE LA CIUDAD DE MÉXICO,artículo anterior\n",
    "\n",
    "NOT ALLOWED - DO NOT USE CURRENT LAW:\n",
    "For text: \"según establece la ley\" → NO OUTPUT (vague reference)\n",
    "For text: \"dicha disposición\" → NO OUTPUT (vague reference) \n",
    "For text: \"la Secretaría debe aprobar\" → NO OUTPUT (entity mention, not legal citation)\n",
    "For text: \"conforme a la normatividad\" → NO OUTPUT (general concept, not specific law)\n",
    "\n",
    "INPUT:\n",
    "{text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64496c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 573 articles in 72 batches using single-pass (0.1 only)...\n",
      "\n",
      "Processing batch 1/72 (articles 1-8)\n",
      "  → Extracting article mentions...\n",
      "    Found 11 mentions\n",
      "\n",
      "Processing batch 2/72 (articles 9-16)\n",
      "  → Extracting article mentions...\n",
      "    Found 16 mentions\n",
      "\n",
      "Processing batch 3/72 (articles 17-24)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 4/72 (articles 25-32)\n",
      "  → Extracting article mentions...\n",
      "    Found 28 mentions\n",
      "\n",
      "Processing batch 5/72 (articles 33-40)\n",
      "  → Extracting article mentions...\n",
      "    Found 11 mentions\n",
      "\n",
      "Processing batch 6/72 (articles 41-48)\n",
      "  → Extracting article mentions...\n",
      "    Found 32 mentions\n",
      "\n",
      "Processing batch 7/72 (articles 49-56)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 8/72 (articles 57-64)\n",
      "  → Extracting article mentions...\n",
      "    Found 15 mentions\n",
      "\n",
      "Processing batch 9/72 (articles 65-72)\n",
      "  → Extracting article mentions...\n",
      "    Found 9 mentions\n",
      "\n",
      "Processing batch 10/72 (articles 73-80)\n",
      "  → Extracting article mentions...\n",
      "    Found 16 mentions\n",
      "\n",
      "Processing batch 11/72 (articles 81-88)\n",
      "  → Extracting article mentions...\n",
      "    Found 4 mentions\n",
      "\n",
      "Processing batch 12/72 (articles 89-96)\n",
      "  → Extracting article mentions...\n",
      "    Found 13 mentions\n",
      "\n",
      "Processing batch 13/72 (articles 97-104)\n",
      "  → Extracting article mentions...\n",
      "    Found 9 mentions\n",
      "\n",
      "Processing batch 14/72 (articles 105-112)\n",
      "  → Extracting article mentions...\n",
      "    Found 15 mentions\n",
      "\n",
      "Processing batch 15/72 (articles 113-120)\n",
      "  → Extracting article mentions...\n",
      "    Found 4 mentions\n",
      "\n",
      "Processing batch 16/72 (articles 121-128)\n",
      "  → Extracting article mentions...\n",
      "    Found 10 mentions\n",
      "\n",
      "Processing batch 17/72 (articles 129-136)\n",
      "  → Extracting article mentions...\n",
      "    Found 9 mentions\n",
      "\n",
      "Processing batch 18/72 (articles 137-144)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 19/72 (articles 145-152)\n",
      "  → Extracting article mentions...\n",
      "    Found 9 mentions\n",
      "\n",
      "Processing batch 20/72 (articles 153-160)\n",
      "  → Extracting article mentions...\n",
      "    Found 11 mentions\n",
      "\n",
      "Processing batch 21/72 (articles 161-168)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 22/72 (articles 169-176)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 23/72 (articles 177-184)\n",
      "  → Extracting article mentions...\n",
      "    Found 15 mentions\n",
      "\n",
      "Processing batch 24/72 (articles 185-192)\n",
      "  → Extracting article mentions...\n",
      "    Found 2 mentions\n",
      "\n",
      "Processing batch 25/72 (articles 193-200)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 26/72 (articles 201-208)\n",
      "  → Extracting article mentions...\n",
      "    Found 4 mentions\n",
      "\n",
      "Processing batch 27/72 (articles 209-216)\n",
      "  → Extracting article mentions...\n",
      "    Found 17 mentions\n",
      "\n",
      "Processing batch 28/72 (articles 217-224)\n",
      "  → Extracting article mentions...\n",
      "    Found 9 mentions\n",
      "\n",
      "Processing batch 29/72 (articles 225-232)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 30/72 (articles 233-240)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 31/72 (articles 241-248)\n",
      "  → Extracting article mentions...\n",
      "    Found 2 mentions\n",
      "\n",
      "Processing batch 32/72 (articles 249-256)\n",
      "  → Extracting article mentions...\n",
      "    Found 2 mentions\n",
      "\n",
      "Processing batch 33/72 (articles 257-264)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 34/72 (articles 265-272)\n",
      "  → Extracting article mentions...\n",
      "    Found 16 mentions\n",
      "\n",
      "Processing batch 35/72 (articles 273-280)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 36/72 (articles 281-288)\n",
      "  → Extracting article mentions...\n",
      "    Found 7 mentions\n",
      "\n",
      "Processing batch 37/72 (articles 289-296)\n",
      "  → Extracting article mentions...\n",
      "    Found 5 mentions\n",
      "\n",
      "Processing batch 38/72 (articles 297-304)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 39/72 (articles 305-312)\n",
      "  → Extracting article mentions...\n",
      "    Found 2 mentions\n",
      "\n",
      "Processing batch 40/72 (articles 313-320)\n",
      "  → Extracting article mentions...\n",
      "    Found 3 mentions\n",
      "\n",
      "Processing batch 41/72 (articles 321-328)\n",
      "  → Extracting article mentions...\n",
      "    Found 6 mentions\n",
      "\n",
      "Processing batch 42/72 (articles 329-336)\n",
      "  → Extracting article mentions...\n",
      "    Found 14 mentions\n",
      "\n",
      "Processing batch 43/72 (articles 337-344)\n",
      "  → Extracting article mentions...\n",
      "    Found 4 mentions\n",
      "\n",
      "Processing batch 44/72 (articles 345-352)\n",
      "  → Extracting article mentions...\n",
      "    Found 14 mentions\n",
      "\n",
      "Processing batch 45/72 (articles 353-360)\n",
      "  → Extracting article mentions...\n",
      "    Found 9 mentions\n",
      "\n",
      "Processing batch 46/72 (articles 361-368)\n",
      "  → Extracting article mentions...\n",
      "    Found 7 mentions\n",
      "\n",
      "Processing batch 47/72 (articles 369-376)\n",
      "  → Extracting article mentions...\n",
      "    Found 13 mentions\n",
      "\n",
      "Processing batch 48/72 (articles 377-384)\n",
      "  → Extracting article mentions...\n",
      "    Found 4 mentions\n",
      "\n",
      "Processing batch 49/72 (articles 385-392)\n",
      "  → Extracting article mentions...\n",
      "    Found 3 mentions\n",
      "\n",
      "Processing batch 50/72 (articles 393-400)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 51/72 (articles 401-408)\n",
      "  → Extracting article mentions...\n",
      "    Found 13 mentions\n",
      "\n",
      "Processing batch 52/72 (articles 409-416)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 53/72 (articles 417-424)\n",
      "  → Extracting article mentions...\n",
      "    Found 11 mentions\n",
      "\n",
      "Processing batch 54/72 (articles 425-432)\n",
      "  → Extracting article mentions...\n",
      "    Found 4 mentions\n",
      "\n",
      "Processing batch 55/72 (articles 433-440)\n",
      "  → Extracting article mentions...\n",
      "    Found 65 mentions\n",
      "\n",
      "Processing batch 56/72 (articles 441-448)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 57/72 (articles 449-456)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 58/72 (articles 457-464)\n",
      "  → Extracting article mentions...\n",
      "    Found 10 mentions\n",
      "\n",
      "Processing batch 59/72 (articles 465-472)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 60/72 (articles 473-480)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 61/72 (articles 481-488)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 62/72 (articles 489-496)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 63/72 (articles 497-504)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 64/72 (articles 505-512)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 65/72 (articles 513-520)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 66/72 (articles 521-528)\n",
      "  → Extracting article mentions...\n",
      "    Found 24 mentions\n",
      "\n",
      "Processing batch 67/72 (articles 529-536)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 68/72 (articles 537-544)\n",
      "  → Extracting article mentions...\n",
      "    Found 8 mentions\n",
      "\n",
      "Processing batch 69/72 (articles 545-552)\n",
      "  → Extracting article mentions...\n",
      "    Found 9 mentions\n",
      "\n",
      "Processing batch 70/72 (articles 553-560)\n",
      "  → Extracting article mentions...\n",
      "    Found 9 mentions\n",
      "\n",
      "Processing batch 71/72 (articles 561-568)\n",
      "  → Extracting article mentions...\n",
      "    Found 7 mentions\n",
      "\n",
      "Processing batch 72/72 (articles 569-573)\n",
      "  → Extracting article mentions...\n",
      "    Found 4 mentions\n",
      "\n",
      "=== EXTRACTION COMPLETE ===\n",
      "Total government entities found: 0\n",
      "Total article mentions found: 728\n",
      "\n",
      "=== QUALITY METRICS ===\n",
      "Unique article mentions: 698\n"
     ]
    }
   ],
   "source": [
    "# Helper function to clean and validate GPT output\n",
    "def clean_csv_output(raw_output, expected_columns):\n",
    "    \"\"\"Clean and validate CSV output from GPT, filtering out artifacts and malformed entries\"\"\"\n",
    "    clean_lines = []\n",
    "    for line in raw_output.strip().splitlines():\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Skip empty lines\n",
    "        if not line:\n",
    "            continue\n",
    "            \n",
    "        # Skip markdown code blocks\n",
    "        if line.startswith('```'):\n",
    "            continue\n",
    "            \n",
    "        # Skip headers (case insensitive)\n",
    "        if line.lower().startswith('art_name') or line.lower().startswith('document'):\n",
    "            continue\n",
    "            \n",
    "        # Skip lines that look like instructions or comments\n",
    "        if line.startswith('#') or line.startswith('//') or line.startswith('OUTPUT') or line.startswith('EXAMPLES'):\n",
    "            continue\n",
    "            \n",
    "        # Must contain commas for CSV format\n",
    "        if ',' not in line:\n",
    "            continue\n",
    "            \n",
    "        # Check if line has the expected number of columns (allow some flexibility)\n",
    "        parts = line.split(',')\n",
    "        if len(parts) < expected_columns:\n",
    "            print(f\"    Skipping malformed line (too few columns): {line[:50]}...\")\n",
    "            continue\n",
    "            \n",
    "        # Clean each part\n",
    "        cleaned_parts = []\n",
    "        for part in parts[:expected_columns]:  # Only take expected number of columns\n",
    "            cleaned_part = part.strip().strip('\"').strip(\"'\")  # Remove quotes and extra spaces\n",
    "            cleaned_parts.append(cleaned_part)\n",
    "            \n",
    "        # Skip if any essential fields are empty (first two columns should not be empty)\n",
    "        if not cleaned_parts[0]:\n",
    "            print(f\"    Skipping line with empty essential fields: {line[:50]}...\")\n",
    "            continue\n",
    "            \n",
    "        # Validate row_id structure (should match pattern like: 12406E12_ARTCULO5)\n",
    "        import re\n",
    "        row_id_pattern = r'^[A-F0-9]{8}_[A-ZÁÉÍÓÚÑÜ]+\\d*$'\n",
    "        if not re.match(row_id_pattern, cleaned_parts[0]):\n",
    "            print(f\"    Skipping line with invalid row_id structure: {line[:50]}...\")\n",
    "            continue\n",
    "            \n",
    "        clean_lines.append(cleaned_parts)\n",
    "    \n",
    "    return clean_lines\n",
    "\n",
    "# CONFIGURATION - Choose extraction mode\n",
    "USE_DUAL_PASS = False  # Set to True for dual-pass (0.1 + 0.3), False for single-pass (0.1 only)\n",
    "\n",
    "# Collectors\n",
    "gov_entities = []\n",
    "article_mentions = []\n",
    "\n",
    "# Batch size - reduced for better quality and completeness\n",
    "BATCH_SIZE = 8  # Even smaller batches for better attention\n",
    "\n",
    "def extract_with_single_pass(batch, prompt_func, expected_columns):\n",
    "    \"\"\"Single-pass extraction with temperature 0.1\"\"\"\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_func(batch)}],\n",
    "        temperature=0.1\n",
    "    )\n",
    "    output = resp.choices[0].message.content.strip()\n",
    "    \n",
    "    if output:\n",
    "        cleaned_output = clean_csv_output(output, expected_columns)\n",
    "        return cleaned_output\n",
    "    return []\n",
    "\n",
    "def extract_with_dual_pass(batch, prompt_func, expected_columns):\n",
    "    \"\"\"Dual-pass extraction with temperatures 0.1 and 0.3\"\"\"\n",
    "    # First pass - standard extraction\n",
    "    resp1 = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_func(batch)}],\n",
    "        temperature=0.1\n",
    "    )\n",
    "    output1 = resp1.choices[0].message.content.strip()\n",
    "    \n",
    "    # Second pass - with different temperature for variation\n",
    "    resp2 = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_func(batch)}],\n",
    "        temperature=0.3  # Higher temperature for different perspective\n",
    "    )\n",
    "    output2 = resp2.choices[0].message.content.strip()\n",
    "    \n",
    "    # Combine both outputs\n",
    "    combined_results = []\n",
    "    if output1:\n",
    "        cleaned_results_1 = clean_csv_output(output1, expected_columns)\n",
    "        combined_results.extend(cleaned_results_1)\n",
    "    if output2:\n",
    "        cleaned_results_2 = clean_csv_output(output2, expected_columns)\n",
    "        combined_results.extend(cleaned_results_2)\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    seen = set()\n",
    "    unique_results = []\n",
    "    for result in combined_results:\n",
    "        result_key = tuple(result)\n",
    "        if result_key not in seen:\n",
    "            seen.add(result_key)\n",
    "            unique_results.append(result)\n",
    "    \n",
    "    return unique_results, len(combined_results)\n",
    "\n",
    "total_batches = (len(df) + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "extraction_mode = \"dual-pass (0.1 + 0.3)\" if USE_DUAL_PASS else \"single-pass (0.1 only)\"\n",
    "print(f\"Processing {len(df)} articles in {total_batches} batches using {extraction_mode}...\")\n",
    "\n",
    "for i, start in enumerate(range(0, len(df), BATCH_SIZE)):\n",
    "    batch = df.iloc[start:start+BATCH_SIZE]\n",
    "    batch_num = i + 1\n",
    "    \n",
    "    print(f\"\\nProcessing batch {batch_num}/{total_batches} (articles {start+1}-{min(start+BATCH_SIZE, len(df))})\")\n",
    "\n",
    "    # Step 1 – Article mentions\n",
    "    print(\"  → Extracting article mentions...\")\n",
    "    try:\n",
    "        if USE_DUAL_PASS:\n",
    "            # Dual-pass extraction\n",
    "            unique_mentions, total_mentions = extract_with_dual_pass(batch, prompt_article_mentions, 4)\n",
    "            print(f\"    Found {len(unique_mentions)} unique mentions (from {total_mentions} total)\")\n",
    "        else:\n",
    "            # Single-pass extraction\n",
    "            unique_mentions = extract_with_single_pass(batch, prompt_article_mentions, 4)\n",
    "            print(f\"    Found {len(unique_mentions)} mentions\")\n",
    "        \n",
    "        article_mentions.extend(unique_mentions)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"    Error extracting mentions: {e}\")\n",
    "    \n",
    "    # Small delay between batches to avoid rate limits\n",
    "    import time\n",
    "    delay = 0.5 if not USE_DUAL_PASS else 1.0  # Longer delay for dual-pass\n",
    "    time.sleep(delay)\n",
    "\n",
    "print(f\"\\n=== EXTRACTION COMPLETE ===\")\n",
    "print(f\"Total government entities found: {len(gov_entities)}\")\n",
    "print(f\"Total article mentions found: {len(article_mentions)}\")\n",
    "\n",
    "# Quality summary\n",
    "print(f\"\\n=== QUALITY METRICS ===\")\n",
    "if gov_entities:\n",
    "    unique_entity_mentions = len(set(tuple(e) for e in gov_entities))\n",
    "    print(f\"Unique government entities: {unique_entity_mentions}\")\n",
    "if article_mentions:\n",
    "    unique_article_mentions = len(set(tuple(m) for m in article_mentions))\n",
    "    print(f\"Unique article mentions: {unique_article_mentions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b122f074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  No government entities to save\n",
      "✅ Saved article mentions to article_mentions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results with proper validation\n",
    "if gov_entities:\n",
    "    entities_df = pd.DataFrame(gov_entities, columns=[\"row_id\", \"mention\"])\n",
    "    entities_df.to_csv(\"/Users/alexa/Projects/cdmx_kg/data/gov_entities_test_01.csv\", index=False, encoding='utf-8')\n",
    "    print(f\"✅ Saved government entities to gov_entities.csv\")\n",
    "else:\n",
    "    print(\"⚠️  No government entities to save\")\n",
    "\n",
    "if article_mentions:\n",
    "    mentions_df = pd.DataFrame(article_mentions, columns=[\"row_id\", \"art_num\", \"law_name\", \"mention_extraction\"])\n",
    "    mentions_df.to_csv(\"/Users/alexa/Projects/cdmx_kg/data/article_mentions_test_01.csv\", index=False, encoding='utf-8')\n",
    "    print(f\"✅ Saved article mentions to article_mentions.csv\")\n",
    "else:\n",
    "    print(\"⚠️  No article mentions to save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3555fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd81a77",
   "metadata": {},
   "source": [
    "# This code section is to use the output of of the identified mentions and classfy them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a740460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For government entities: \n",
    "# Read the dictionary of the document.\n",
    "# Then, go to the list of entities and check if it is needed to change the mention name based on the dictionary.\n",
    "# Replace the name if needed.\n",
    "# Not all the mentions will be needed to be changed, only ones specifiqued for each document. \n",
    "\n",
    "# Then, look at the list of mentions and create a new list with the id_hash for each differnte entity.\n",
    "# Add the hash_id to the list of mentions based on the entity name. \n",
    "# The output is the list of mentions with the hash_id for each entity and the list of unique entities with the hash_id.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4d07b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdmx_kg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
