{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b95a753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting article extraction process at 15:48:02\n",
      "ğŸ“Š Data loaded: 11130 rows\n",
      "ğŸ“‹ Columns available: ['row_id', 'doc_hash', 'document_name', 'document_section_title', 'text']\n",
      "â±ï¸  Data loading took: 0.12 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"ğŸš€ Starting article extraction process at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "start_time = time.time()\n",
    "\n",
    "df = pd.read_csv('/Users/alexa/Projects/cdmx_kg/data/identifiers_0_half.csv')\n",
    "\n",
    "print(f\"ğŸ“Š Data loaded: {len(df)} rows\")\n",
    "print(f\"ğŸ“‹ Columns available: {list(df.columns)}\")\n",
    "print(f\"â±ï¸  Data loading took: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39f4e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FUNCIÃ“N MEJORADA DE ARTÃCULOS INTEGRADA\n",
      "   - Detecta mÃºltiples artÃ­culos: 'artÃ­culos 50 y 325'\n",
      "   - Contexto dual: 30 palabras + 300 caracteres\n",
      "   - 3 patrones diferentes para mayor cobertura\n"
     ]
    }
   ],
   "source": [
    "def extract_article_mentions_improved(df, text_column='text', section_column='document_section_title'):\n",
    "    \"\"\"\n",
    "    VERSIÃ“N MEJORADA: Detecta mÃºltiples artÃ­culos y ofrece contexto flexible\n",
    "    \n",
    "    MEJORAS:\n",
    "    1. âœ… Detecta \"artÃ­culos 50 y 325\" \n",
    "    2. âœ… Contexto por caracteres (300) ademÃ¡s de palabras (30)\n",
    "    3. âœ… MÃºltiples patrones para casos complejos\n",
    "    4. âœ… Tracking de tiempo y progreso\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nğŸ” Starting article extraction from {len(df)} rows...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # PATRONES MEJORADOS\n",
    "    article_patterns = [\n",
    "        # PatrÃ³n 1: MÃºltiples artÃ­culos con conectores\n",
    "        r'\\b(?:art[Ã­i]culos?|art\\.?)\\s*\\d+(?:\\s*[Â°Âº])?(?:\\s*bis|ter|qu[aÃ¡]ter)?(?:\\s*(?:y|al|,)\\s*\\d+(?:\\s*[Â°Âº])?(?:\\s*bis|ter|qu[aÃ¡]ter)?)*',\n",
    "        \n",
    "        # PatrÃ³n 2: Rangos \"del 10 al 15\"  \n",
    "        r'\\b(?:art[Ã­i]culos?|art\\.?)\\s*(?:del\\s*)?\\d+(?:\\s*[Â°Âº])?(?:\\s*bis|ter|qu[aÃ¡]ter)?\\s*al\\s*\\d+(?:\\s*[Â°Âº])?(?:\\s*bis|ter|qu[aÃ¡]ter)?',\n",
    "        \n",
    "        # PatrÃ³n 3: Individual (respaldo)\n",
    "        r'\\b(?:art[Ã­i]culos?|art\\.?)\\s*\\d+(?:\\s*[Â°Âº])?(?:\\s*bis|ter|qu[aÃ¡]ter)?'\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    processed_rows = 0\n",
    "    rows_with_matches = 0\n",
    "    total_matches = 0\n",
    "    \n",
    "    # Progress tracking\n",
    "    total_rows = len(df)\n",
    "    progress_interval = max(1, total_rows // 20)  # Show progress every 5%\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        processed_rows += 1\n",
    "        \n",
    "        # Progress indicator\n",
    "        if processed_rows % progress_interval == 0:\n",
    "            progress = (processed_rows / total_rows) * 100\n",
    "            elapsed = time.time() - start_time\n",
    "            rate = processed_rows / elapsed if elapsed > 0 else 0\n",
    "            eta = (total_rows - processed_rows) / rate if rate > 0 else 0\n",
    "            print(f\"â³ Progress: {progress:.1f}% ({processed_rows}/{total_rows}) | \"\n",
    "                  f\"Rate: {rate:.1f} rows/sec | ETA: {eta:.1f}s | Matches: {total_matches}\")\n",
    "        \n",
    "        text = str(row[text_column]) if pd.notna(row[text_column]) else \"\"\n",
    "        section_title = row[section_column] if pd.notna(row[section_column]) else \"\"\n",
    "        \n",
    "        # Use existing columns directly (since they exist in the data)\n",
    "        doc_hash = row['doc_hash']\n",
    "        row_id = row['row_id']\n",
    "        \n",
    "        if not text.strip():\n",
    "            continue\n",
    "            \n",
    "        # Aplicar patrones (evita duplicados con set)\n",
    "        found_matches = set()\n",
    "        row_match_count = 0\n",
    "        \n",
    "        for pattern_idx, pattern in enumerate(article_patterns):\n",
    "            matches = re.finditer(pattern, text, re.IGNORECASE)\n",
    "            \n",
    "            for match in matches:\n",
    "                match_key = (match.start(), match.end(), match.group(0))\n",
    "                if match_key in found_matches:\n",
    "                    continue\n",
    "                found_matches.add(match_key)\n",
    "                \n",
    "                matched_text = match.group(0)\n",
    "                \n",
    "                # CONTEXTO MEJORADO: 30 palabras + 300 caracteres\n",
    "                context_words = get_word_context(text, match, 30)\n",
    "                context_chars = get_char_context(text, match, 300)\n",
    "                \n",
    "                results.append({\n",
    "                    'doc_hash': doc_hash,\n",
    "                    'row_id': row_id,\n",
    "                    'pattern_type': f\"Pattern_{pattern_idx + 1}\",\n",
    "                    #'document_section_title': section_title,\n",
    "                    'matched_text': matched_text,\n",
    "                    'context_30_words': context_words,\n",
    "                    'context_300_chars': context_chars,\n",
    "                    #'start_char': match.start(),\n",
    "                    #'end_char': match.end(),\n",
    "                })\n",
    "                row_match_count += 1\n",
    "                total_matches += 1\n",
    "        \n",
    "        if row_match_count > 0:\n",
    "            rows_with_matches += 1\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nâœ… Extraction completed!\")\n",
    "    print(f\"â±ï¸  Total time: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"ğŸ“Š Processed: {processed_rows} rows\")\n",
    "    print(f\"ğŸ¯ Rows with matches: {rows_with_matches} ({rows_with_matches/processed_rows*100:.1f}%)\")\n",
    "    print(f\"ğŸ”¢ Total matches found: {total_matches}\")\n",
    "    print(f\"âš¡ Processing rate: {processed_rows/elapsed_time:.1f} rows/second\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def get_word_context(text, match, num_words):\n",
    "    \"\"\"Contexto por palabras\"\"\"\n",
    "    words = text.split()\n",
    "    text_before_match = text[:match.start()]\n",
    "    text_after_match = text[match.end():]\n",
    "    \n",
    "    words_before = text_before_match.split()[-num_words:] if text_before_match else []\n",
    "    words_after = text_after_match.split()[:num_words] if text_after_match else []\n",
    "    \n",
    "    before = \" \".join(words_before)\n",
    "    after = \" \".join(words_after)\n",
    "    \n",
    "    return f\"{before} **{match.group(0)}** {after}\".strip()\n",
    "\n",
    "def get_char_context(text, match, num_chars):\n",
    "    \"\"\"Contexto por caracteres\"\"\"\n",
    "    start = max(0, match.start() - num_chars)\n",
    "    end = min(len(text), match.end() + num_chars)\n",
    "    \n",
    "    before = text[start:match.start()]\n",
    "    after = text[match.end():end]\n",
    "    \n",
    "    return f\"{before}**{match.group(0)}**{after}\"\n",
    "\n",
    "print(\"âœ… FUNCIÃ“N MEJORADA DE ARTÃCULOS INTEGRADA\")\n",
    "print(\"   - Detecta mÃºltiples artÃ­culos: 'artÃ­culos 50 y 325'\")\n",
    "print(\"   - Contexto dual: 30 palabras + 300 caracteres\")\n",
    "print(\"   - 3 patrones diferentes para mayor cobertura\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec3a6198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Starting article extraction from 11130 rows...\n",
      "â³ Progress: 5.0% (556/11130) | Rate: 12913.2 rows/sec | ETA: 0.8s | Matches: 72\n",
      "â³ Progress: 10.0% (1112/11130) | Rate: 13247.6 rows/sec | ETA: 0.8s | Matches: 234\n",
      "â³ Progress: 15.0% (1668/11130) | Rate: 12523.2 rows/sec | ETA: 0.8s | Matches: 432\n",
      "â³ Progress: 20.0% (2224/11130) | Rate: 10479.8 rows/sec | ETA: 0.8s | Matches: 705\n",
      "â³ Progress: 25.0% (2780/11130) | Rate: 10688.9 rows/sec | ETA: 0.8s | Matches: 856\n",
      "â³ Progress: 30.0% (3336/11130) | Rate: 11111.5 rows/sec | ETA: 0.7s | Matches: 951\n",
      "â³ Progress: 35.0% (3892/11130) | Rate: 11655.4 rows/sec | ETA: 0.6s | Matches: 1022\n",
      "â³ Progress: 40.0% (4448/11130) | Rate: 11698.1 rows/sec | ETA: 0.6s | Matches: 1121\n",
      "â³ Progress: 45.0% (5004/11130) | Rate: 11630.5 rows/sec | ETA: 0.5s | Matches: 1342\n",
      "â³ Progress: 50.0% (5560/11130) | Rate: 11795.3 rows/sec | ETA: 0.5s | Matches: 1480\n",
      "â³ Progress: 55.0% (6116/11130) | Rate: 11950.8 rows/sec | ETA: 0.4s | Matches: 1566\n",
      "â³ Progress: 59.9% (6672/11130) | Rate: 11914.1 rows/sec | ETA: 0.4s | Matches: 1673\n",
      "â³ Progress: 64.9% (7228/11130) | Rate: 12039.6 rows/sec | ETA: 0.3s | Matches: 1855\n",
      "â³ Progress: 69.9% (7784/11130) | Rate: 12219.0 rows/sec | ETA: 0.3s | Matches: 1933\n",
      "â³ Progress: 74.9% (8340/11130) | Rate: 11928.4 rows/sec | ETA: 0.2s | Matches: 2105\n",
      "â³ Progress: 79.9% (8896/11130) | Rate: 12062.5 rows/sec | ETA: 0.2s | Matches: 2291\n",
      "â³ Progress: 84.9% (9452/11130) | Rate: 11991.5 rows/sec | ETA: 0.1s | Matches: 2384\n",
      "â³ Progress: 89.9% (10008/11130) | Rate: 11360.0 rows/sec | ETA: 0.1s | Matches: 2689\n",
      "â³ Progress: 94.9% (10564/11130) | Rate: 11474.1 rows/sec | ETA: 0.0s | Matches: 2804\n",
      "â³ Progress: 99.9% (11120/11130) | Rate: 11470.2 rows/sec | ETA: 0.0s | Matches: 3070\n",
      "\n",
      "âœ… Extraction completed!\n",
      "â±ï¸  Total time: 0.97 seconds\n",
      "ğŸ“Š Processed: 11130 rows\n",
      "ğŸ¯ Rows with matches: 1151 (10.3%)\n",
      "ğŸ”¢ Total matches found: 3077\n",
      "âš¡ Processing rate: 11473.6 rows/second\n",
      "\n",
      "ğŸ“ˆ FINAL RESULTS:\n",
      "ğŸ”¢ Total mentions extracted: 3077\n",
      "â±ï¸  Total extraction time: 0.97 seconds\n",
      "\n",
      "ğŸ“‹ Sample of extracted data:\n",
      "ğŸ“Š Pattern distribution:\n",
      "   Pattern_1: 2856 matches (92.8%)\n",
      "   Pattern_3: 220 matches (7.1%)\n",
      "   Pattern_2: 1 matches (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Execute the extraction with timing\n",
    "extraction_start = time.time()\n",
    "mentions_df = extract_article_mentions_improved(df)\n",
    "extraction_time = time.time() - extraction_start\n",
    "\n",
    "print(f\"\\nğŸ“ˆ FINAL RESULTS:\")\n",
    "print(f\"ğŸ”¢ Total mentions extracted: {len(mentions_df)}\")\n",
    "print(f\"â±ï¸  Total extraction time: {extraction_time:.2f} seconds\")\n",
    "\n",
    "if len(mentions_df) > 0:\n",
    "    print(f\"\\nğŸ“‹ Sample of extracted data:\")\n",
    "    print(f\"ğŸ“Š Pattern distribution:\")\n",
    "    pattern_counts = mentions_df['pattern_type'].value_counts()\n",
    "    for pattern, count in pattern_counts.items():\n",
    "        print(f\"   {pattern}: {count} matches ({count/len(mentions_df)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"âš ï¸  No article mentions found in the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd2ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª TEST CASE: Your specific example\n",
    "test_text = \"Consejo de Salud del Distrito Federal: al Consejo integrado en tÃ©rminos de los artÃ­culos 22 y 23 de la Ley de Salud del Distrito Federal;\"\n",
    "\n",
    "print(\"ğŸ§ª TESTING CURRENT PATTERNS:\")\n",
    "print(f\"Test text: {test_text}\")\n",
    "print()\n",
    "\n",
    "# Current patterns from the function\n",
    "article_patterns = [\n",
    "    # PatrÃ³n 1: MÃºltiples artÃ­culos con conectores\n",
    "    r'\\b(?:art[Ã­i]culos?|art\\.?)\\s*\\d+(?:\\s*[Â°Âº])?(?:\\s*bis|ter|qu[aÃ¡]ter)?(?:\\s*(?:y|al|,)\\s*\\d+(?:\\s*[Â°Âº])?(?:\\s*bis|ter|qu[aÃ¡]ter)?)*',\n",
    "    \n",
    "    # PatrÃ³n 2: Rangos \"del 10 al 15\"  \n",
    "    r'\\b(?:art[Ã­i]culos?|art\\.?)\\s*(?:del\\s*)?\\d+(?:\\s*[Â°Âº])?(?:\\s*bis|ter|qu[aÃ¡]ter)?\\s*al\\s*\\d+(?:\\s*[Â°Âº])?(?:\\s*bis|ter|qu[aÃ¡]ter)?',\n",
    "    \n",
    "    # PatrÃ³n 3: Individual (respaldo)\n",
    "    r'\\b(?:art[Ã­i]culos?|art\\.?)\\s*\\d+(?:\\s*[Â°Âº])?(?:\\s*bis|ter|qu[aÃ¡]ter)?'\n",
    "]\n",
    "\n",
    "for i, pattern in enumerate(article_patterns, 1):\n",
    "    matches = re.findall(pattern, test_text, re.IGNORECASE)\n",
    "    print(f\"Pattern {i}: {matches}\")\n",
    "    if matches:\n",
    "        print(f\"  âœ… Found: {matches[0]}\")\n",
    "    else:\n",
    "        print(f\"  âŒ No match\")\n",
    "    print()\n",
    "\n",
    "# Test additional challenging cases\n",
    "print(\"ğŸ§ª TESTING ADDITIONAL EDGE CASES:\")\n",
    "edge_cases = [\n",
    "    \"segÃºn el artÃ­culo 15 bis y 16 ter de la constituciÃ³n\",\n",
    "    \"conforme a los artÃ­culos 1Â°, 2Â°, y 3Â° del reglamento\", \n",
    "    \"artÃ­culos del 50 al 75 de la ley general\",\n",
    "    \"art. 123, 124 y 125 establecen que...\",\n",
    "    \"Los artÃ­culos 1, 2, 3, 4 y 5 determinan\",\n",
    "    \"artÃ­culo 25 quÃ¡ter de la ley ambiental\"\n",
    "]\n",
    "\n",
    "for case in edge_cases:\n",
    "    print(f\"Text: {case}\")\n",
    "    for i, pattern in enumerate(article_patterns, 1):\n",
    "        matches = re.findall(pattern, case, re.IGNORECASE)\n",
    "        if matches:\n",
    "            print(f\"  Pattern {i} âœ…: {matches[0]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5724b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’¡ SUGGESTED IMPROVEMENTS FOR BETTER COVERAGE\n",
    "\n",
    "print(\"ğŸ’¡ IMPROVED PATTERNS:\")\n",
    "\n",
    "# Enhanced patterns with better coverage\n",
    "improved_patterns = [\n",
    "    # Pattern 1: Multiple articles with various connectors (improved)\n",
    "    r'\\b(?:art[Ã­i]culos?|art\\.?)\\s*\\d+(?:\\s*[Â°Âº])?(?:\\s*bis|ter|qu[aÃ¡]ter)?(?:\\s*(?:y|e|al|,|;)\\s*\\d+(?:\\s*[Â°Âº])?(?:\\s*bis|ter|qu[aÃ¡]ter)?)*',\n",
    "    \n",
    "    # Pattern 2: Ranges with \"del X al Y\" or \"X al Y\"\n",
    "    r'\\b(?:art[Ã­i]culos?|art\\.?)\\s*(?:del\\s*)?\\d+(?:\\s*[Â°Âº])?(?:\\s*bis|ter|qu[aÃ¡]ter)?\\s*al\\s*\\d+(?:\\s*[Â°Âº])?(?:\\s*bis|ter|qu[aÃ¡]ter)?',\n",
    "    \n",
    "    # Pattern 3: Comma-separated lists (1, 2, 3, 4 y 5)\n",
    "    r'\\b(?:art[Ã­i]culos?|art\\.?)\\s*\\d+(?:\\s*[Â°Âº])?(?:\\s*bis|ter|qu[aÃ¡]ter)?(?:\\s*,\\s*\\d+(?:\\s*[Â°Âº])?(?:\\s*bis|ter|qu[aÃ¡]ter)?)*(?:\\s*(?:y|e)\\s*\\d+(?:\\s*[Â°Âº])?(?:\\s*bis|ter|qu[aÃ¡]ter)?)?',\n",
    "    \n",
    "    # Pattern 4: Individual articles (backup)\n",
    "    r'\\b(?:art[Ã­i]culos?|art\\.?)\\s*\\d+(?:\\s*[Â°Âº])?(?:\\s*bis|ter|qu[aÃ¡]ter)?'\n",
    "]\n",
    "\n",
    "print(\"Testing improved patterns:\")\n",
    "test_cases_all = [\n",
    "    \"artÃ­culos 22 y 23 de la Ley\",\n",
    "    \"segÃºn el artÃ­culo 15 bis y 16 ter\",\n",
    "    \"artÃ­culos 1Â°, 2Â°, y 3Â° del reglamento\", \n",
    "    \"artÃ­culos del 50 al 75 de la ley\",\n",
    "    \"art. 123, 124 y 125 establecen\",\n",
    "    \"artÃ­culos 1, 2, 3, 4 y 5 determinan\",\n",
    "    \"artÃ­culo 25 quÃ¡ter de la ley\"\n",
    "]\n",
    "\n",
    "for case in test_cases_all:\n",
    "    print(f\"\\nText: {case}\")\n",
    "    for i, pattern in enumerate(improved_patterns, 1):\n",
    "        matches = re.findall(pattern, case, re.IGNORECASE)\n",
    "        if matches:\n",
    "            print(f\"  Improved Pattern {i} âœ…: {matches[0]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ” RECOMMENDATIONS:\")\n",
    "print(\"1. âœ… Your current patterns should work for 'artÃ­culos 22 y 23'\")\n",
    "print(\"2. ğŸ’¡ Consider adding comma-separated pattern for complex lists\")\n",
    "print(\"3. ğŸ”§ Add 'e' as alternative to 'y' (Spanish grammar)\")\n",
    "print(\"4. ğŸ“ Consider semicolon (;) as separator in formal texts\")\n",
    "print(\"5. ğŸ¯ Pattern priority: Most specific â†’ Most general\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8197c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mentions_df = mentions_df[['entity_id','source_row_id','original_text','entity_text', 'entity_label','pattern_group']]\n",
    "mentions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ee79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save entity recognition results with IDs\n",
    "\n",
    "mentions_output = '/Users/alexa/Projects/cdmx_kg/data/mentions_extracted_complete.csv'\n",
    "mentions_df.to_csv(mentions_output, index=False, encoding='utf-8-sig')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdmx_kg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
