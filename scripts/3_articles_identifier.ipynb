{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b95a753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting article extraction process at 15:48:02\n",
      "üìä Data loaded: 11130 rows\n",
      "üìã Columns available: ['row_id', 'doc_hash', 'document_name', 'document_section_title', 'text']\n",
      "‚è±Ô∏è  Data loading took: 0.12 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"üöÄ Starting article extraction process at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "start_time = time.time()\n",
    "\n",
    "df = pd.read_csv('/Users/alexa/Projects/cdmx_kg/data/identifiers_0_half.csv')\n",
    "\n",
    "print(f\"üìä Data loaded: {len(df)} rows\")\n",
    "print(f\"üìã Columns available: {list(df.columns)}\")\n",
    "print(f\"‚è±Ô∏è  Data loading took: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39f4e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FUNCI√ìN MEJORADA DE ART√çCULOS INTEGRADA\n",
      "   - Detecta m√∫ltiples art√≠culos: 'art√≠culos 50 y 325'\n",
      "   - Contexto dual: 30 palabras + 300 caracteres\n",
      "   - 3 patrones diferentes para mayor cobertura\n"
     ]
    }
   ],
   "source": [
    "def extract_article_mentions_improved(df, text_column='text', section_column='document_section_title'):\n",
    "    \"\"\"\n",
    "    VERSI√ìN MEJORADA: Detecta m√∫ltiples art√≠culos y ofrece contexto flexible\n",
    "    \n",
    "    MEJORAS:\n",
    "    1. ‚úÖ Detecta \"art√≠culos 50 y 325\" \n",
    "    2. ‚úÖ Contexto por caracteres (300) adem√°s de palabras (30)\n",
    "    3. ‚úÖ M√∫ltiples patrones para casos complejos\n",
    "    4. ‚úÖ Tracking de tiempo y progreso\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nüîç Starting article extraction from {len(df)} rows...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # PATRONES MEJORADOS\n",
    "    article_patterns = [\n",
    "        # Patr√≥n 1: M√∫ltiples art√≠culos con conectores\n",
    "        r'\\b(?:art[√≠i]culos?|art\\.?)\\s*\\d+(?:\\s*[¬∞¬∫])?(?:\\s*bis|ter|qu[a√°]ter)?(?:\\s*(?:y|al|,)\\s*\\d+(?:\\s*[¬∞¬∫])?(?:\\s*bis|ter|qu[a√°]ter)?)*',\n",
    "        \n",
    "        # Patr√≥n 2: Rangos \"del 10 al 15\"  \n",
    "        r'\\b(?:art[√≠i]culos?|art\\.?)\\s*(?:del\\s*)?\\d+(?:\\s*[¬∞¬∫])?(?:\\s*bis|ter|qu[a√°]ter)?\\s*al\\s*\\d+(?:\\s*[¬∞¬∫])?(?:\\s*bis|ter|qu[a√°]ter)?',\n",
    "        \n",
    "        # Patr√≥n 3: Individual (respaldo)\n",
    "        r'\\b(?:art[√≠i]culos?|art\\.?)\\s*\\d+(?:\\s*[¬∞¬∫])?(?:\\s*bis|ter|qu[a√°]ter)?'\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    processed_rows = 0\n",
    "    rows_with_matches = 0\n",
    "    total_matches = 0\n",
    "    \n",
    "    # Progress tracking\n",
    "    total_rows = len(df)\n",
    "    progress_interval = max(1, total_rows // 20)  # Show progress every 5%\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        processed_rows += 1\n",
    "        \n",
    "        # Progress indicator\n",
    "        if processed_rows % progress_interval == 0:\n",
    "            progress = (processed_rows / total_rows) * 100\n",
    "            elapsed = time.time() - start_time\n",
    "            rate = processed_rows / elapsed if elapsed > 0 else 0\n",
    "            eta = (total_rows - processed_rows) / rate if rate > 0 else 0\n",
    "            print(f\"‚è≥ Progress: {progress:.1f}% ({processed_rows}/{total_rows}) | \"\n",
    "                  f\"Rate: {rate:.1f} rows/sec | ETA: {eta:.1f}s | Matches: {total_matches}\")\n",
    "        \n",
    "        text = str(row[text_column]) if pd.notna(row[text_column]) else \"\"\n",
    "        section_title = row[section_column] if pd.notna(row[section_column]) else \"\"\n",
    "        \n",
    "        # Use existing columns directly (since they exist in the data)\n",
    "        doc_hash = row['doc_hash']\n",
    "        row_id = row['row_id']\n",
    "        \n",
    "        if not text.strip():\n",
    "            continue\n",
    "            \n",
    "        # Aplicar patrones (evita duplicados con set)\n",
    "        found_matches = set()\n",
    "        row_match_count = 0\n",
    "        \n",
    "        for pattern_idx, pattern in enumerate(article_patterns):\n",
    "            matches = re.finditer(pattern, text, re.IGNORECASE)\n",
    "            \n",
    "            for match in matches:\n",
    "                match_key = (match.start(), match.end(), match.group(0))\n",
    "                if match_key in found_matches:\n",
    "                    continue\n",
    "                found_matches.add(match_key)\n",
    "                \n",
    "                matched_text = match.group(0)\n",
    "                \n",
    "                # CONTEXTO MEJORADO: 30 palabras + 300 caracteres\n",
    "                context_words = get_word_context(text, match, 30)\n",
    "                context_chars = get_char_context(text, match, 300)\n",
    "                \n",
    "                results.append({\n",
    "                    'doc_hash': doc_hash,\n",
    "                    'row_id': row_id,\n",
    "                    'pattern_type': f\"Pattern_{pattern_idx + 1}\",\n",
    "                    #'document_section_title': section_title,\n",
    "                    'matched_text': matched_text,\n",
    "                    'context_30_words': context_words,\n",
    "                    'context_300_chars': context_chars,\n",
    "                    #'start_char': match.start(),\n",
    "                    #'end_char': match.end(),\n",
    "                })\n",
    "                row_match_count += 1\n",
    "                total_matches += 1\n",
    "        \n",
    "        if row_match_count > 0:\n",
    "            rows_with_matches += 1\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n‚úÖ Extraction completed!\")\n",
    "    print(f\"‚è±Ô∏è  Total time: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"üìä Processed: {processed_rows} rows\")\n",
    "    print(f\"üéØ Rows with matches: {rows_with_matches} ({rows_with_matches/processed_rows*100:.1f}%)\")\n",
    "    print(f\"üî¢ Total matches found: {total_matches}\")\n",
    "    print(f\"‚ö° Processing rate: {processed_rows/elapsed_time:.1f} rows/second\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def get_word_context(text, match, num_words):\n",
    "    \"\"\"Contexto por palabras\"\"\"\n",
    "    words = text.split()\n",
    "    text_before_match = text[:match.start()]\n",
    "    text_after_match = text[match.end():]\n",
    "    \n",
    "    words_before = text_before_match.split()[-num_words:] if text_before_match else []\n",
    "    words_after = text_after_match.split()[:num_words] if text_after_match else []\n",
    "    \n",
    "    before = \" \".join(words_before)\n",
    "    after = \" \".join(words_after)\n",
    "    \n",
    "    return f\"{before} **{match.group(0)}** {after}\".strip()\n",
    "\n",
    "def get_char_context(text, match, num_chars):\n",
    "    \"\"\"Contexto por caracteres\"\"\"\n",
    "    start = max(0, match.start() - num_chars)\n",
    "    end = min(len(text), match.end() + num_chars)\n",
    "    \n",
    "    before = text[start:match.start()]\n",
    "    after = text[match.end():end]\n",
    "    \n",
    "    return f\"{before}**{match.group(0)}**{after}\"\n",
    "\n",
    "print(\"‚úÖ FUNCI√ìN MEJORADA DE ART√çCULOS INTEGRADA\")\n",
    "print(\"   - Detecta m√∫ltiples art√≠culos: 'art√≠culos 50 y 325'\")\n",
    "print(\"   - Contexto dual: 30 palabras + 300 caracteres\")\n",
    "print(\"   - 3 patrones diferentes para mayor cobertura\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec3a6198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Starting article extraction from 11130 rows...\n",
      "‚è≥ Progress: 5.0% (556/11130) | Rate: 12913.2 rows/sec | ETA: 0.8s | Matches: 72\n",
      "‚è≥ Progress: 10.0% (1112/11130) | Rate: 13247.6 rows/sec | ETA: 0.8s | Matches: 234\n",
      "‚è≥ Progress: 15.0% (1668/11130) | Rate: 12523.2 rows/sec | ETA: 0.8s | Matches: 432\n",
      "‚è≥ Progress: 20.0% (2224/11130) | Rate: 10479.8 rows/sec | ETA: 0.8s | Matches: 705\n",
      "‚è≥ Progress: 25.0% (2780/11130) | Rate: 10688.9 rows/sec | ETA: 0.8s | Matches: 856\n",
      "‚è≥ Progress: 30.0% (3336/11130) | Rate: 11111.5 rows/sec | ETA: 0.7s | Matches: 951\n",
      "‚è≥ Progress: 35.0% (3892/11130) | Rate: 11655.4 rows/sec | ETA: 0.6s | Matches: 1022\n",
      "‚è≥ Progress: 40.0% (4448/11130) | Rate: 11698.1 rows/sec | ETA: 0.6s | Matches: 1121\n",
      "‚è≥ Progress: 45.0% (5004/11130) | Rate: 11630.5 rows/sec | ETA: 0.5s | Matches: 1342\n",
      "‚è≥ Progress: 50.0% (5560/11130) | Rate: 11795.3 rows/sec | ETA: 0.5s | Matches: 1480\n",
      "‚è≥ Progress: 55.0% (6116/11130) | Rate: 11950.8 rows/sec | ETA: 0.4s | Matches: 1566\n",
      "‚è≥ Progress: 59.9% (6672/11130) | Rate: 11914.1 rows/sec | ETA: 0.4s | Matches: 1673\n",
      "‚è≥ Progress: 64.9% (7228/11130) | Rate: 12039.6 rows/sec | ETA: 0.3s | Matches: 1855\n",
      "‚è≥ Progress: 69.9% (7784/11130) | Rate: 12219.0 rows/sec | ETA: 0.3s | Matches: 1933\n",
      "‚è≥ Progress: 74.9% (8340/11130) | Rate: 11928.4 rows/sec | ETA: 0.2s | Matches: 2105\n",
      "‚è≥ Progress: 79.9% (8896/11130) | Rate: 12062.5 rows/sec | ETA: 0.2s | Matches: 2291\n",
      "‚è≥ Progress: 84.9% (9452/11130) | Rate: 11991.5 rows/sec | ETA: 0.1s | Matches: 2384\n",
      "‚è≥ Progress: 89.9% (10008/11130) | Rate: 11360.0 rows/sec | ETA: 0.1s | Matches: 2689\n",
      "‚è≥ Progress: 94.9% (10564/11130) | Rate: 11474.1 rows/sec | ETA: 0.0s | Matches: 2804\n",
      "‚è≥ Progress: 99.9% (11120/11130) | Rate: 11470.2 rows/sec | ETA: 0.0s | Matches: 3070\n",
      "\n",
      "‚úÖ Extraction completed!\n",
      "‚è±Ô∏è  Total time: 0.97 seconds\n",
      "üìä Processed: 11130 rows\n",
      "üéØ Rows with matches: 1151 (10.3%)\n",
      "üî¢ Total matches found: 3077\n",
      "‚ö° Processing rate: 11473.6 rows/second\n",
      "\n",
      "üìà FINAL RESULTS:\n",
      "üî¢ Total mentions extracted: 3077\n",
      "‚è±Ô∏è  Total extraction time: 0.97 seconds\n",
      "\n",
      "üìã Sample of extracted data:\n",
      "üìä Pattern distribution:\n",
      "   Pattern_1: 2856 matches (92.8%)\n",
      "   Pattern_3: 220 matches (7.1%)\n",
      "   Pattern_2: 1 matches (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Execute the extraction with timing\n",
    "extraction_start = time.time()\n",
    "mentions_df = extract_article_mentions_improved(df)\n",
    "extraction_time = time.time() - extraction_start\n",
    "\n",
    "print(f\"\\nüìà FINAL RESULTS:\")\n",
    "print(f\"üî¢ Total mentions extracted: {len(mentions_df)}\")\n",
    "print(f\"‚è±Ô∏è  Total extraction time: {extraction_time:.2f} seconds\")\n",
    "\n",
    "if len(mentions_df) > 0:\n",
    "    print(f\"\\nüìã Sample of extracted data:\")\n",
    "    print(f\"üìä Pattern distribution:\")\n",
    "    pattern_counts = mentions_df['pattern_type'].value_counts()\n",
    "    for pattern, count in pattern_counts.items():\n",
    "        print(f\"   {pattern}: {count} matches ({count/len(mentions_df)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No article mentions found in the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd2ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ TEST CASE: Your specific example\n",
    "test_text = \"Consejo de Salud del Distrito Federal: al Consejo integrado en t√©rminos de los art√≠culos 22 y 23 de la Ley de Salud del Distrito Federal;\"\n",
    "\n",
    "print(\"üß™ TESTING CURRENT PATTERNS:\")\n",
    "print(f\"Test text: {test_text}\")\n",
    "print()\n",
    "\n",
    "# Current patterns from the function\n",
    "article_patterns = [\n",
    "    # Patr√≥n 1: M√∫ltiples art√≠culos con conectores\n",
    "    r'\\b(?:art[√≠i]culos?|art\\.?)\\s*\\d+(?:\\s*[¬∞¬∫])?(?:\\s*bis|ter|qu[a√°]ter)?(?:\\s*(?:y|al|,)\\s*\\d+(?:\\s*[¬∞¬∫])?(?:\\s*bis|ter|qu[a√°]ter)?)*',\n",
    "    \n",
    "    # Patr√≥n 2: Rangos \"del 10 al 15\"  \n",
    "    r'\\b(?:art[√≠i]culos?|art\\.?)\\s*(?:del\\s*)?\\d+(?:\\s*[¬∞¬∫])?(?:\\s*bis|ter|qu[a√°]ter)?\\s*al\\s*\\d+(?:\\s*[¬∞¬∫])?(?:\\s*bis|ter|qu[a√°]ter)?',\n",
    "    \n",
    "    # Patr√≥n 3: Individual (respaldo)\n",
    "    r'\\b(?:art[√≠i]culos?|art\\.?)\\s*\\d+(?:\\s*[¬∞¬∫])?(?:\\s*bis|ter|qu[a√°]ter)?'\n",
    "]\n",
    "\n",
    "for i, pattern in enumerate(article_patterns, 1):\n",
    "    matches = re.findall(pattern, test_text, re.IGNORECASE)\n",
    "    print(f\"Pattern {i}: {matches}\")\n",
    "    if matches:\n",
    "        print(f\"  ‚úÖ Found: {matches[0]}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå No match\")\n",
    "    print()\n",
    "\n",
    "# Test additional challenging cases\n",
    "print(\"üß™ TESTING ADDITIONAL EDGE CASES:\")\n",
    "edge_cases = [\n",
    "    \"seg√∫n el art√≠culo 15 bis y 16 ter de la constituci√≥n\",\n",
    "    \"conforme a los art√≠culos 1¬∞, 2¬∞, y 3¬∞ del reglamento\", \n",
    "    \"art√≠culos del 50 al 75 de la ley general\",\n",
    "    \"art. 123, 124 y 125 establecen que...\",\n",
    "    \"Los art√≠culos 1, 2, 3, 4 y 5 determinan\",\n",
    "    \"art√≠culo 25 qu√°ter de la ley ambiental\"\n",
    "]\n",
    "\n",
    "for case in edge_cases:\n",
    "    print(f\"Text: {case}\")\n",
    "    for i, pattern in enumerate(article_patterns, 1):\n",
    "        matches = re.findall(pattern, case, re.IGNORECASE)\n",
    "        if matches:\n",
    "            print(f\"  Pattern {i} ‚úÖ: {matches[0]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5724b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üí° SUGGESTED IMPROVEMENTS FOR BETTER COVERAGE\n",
    "\n",
    "print(\"üí° IMPROVED PATTERNS:\")\n",
    "\n",
    "# Enhanced patterns with better coverage\n",
    "improved_patterns = [\n",
    "    # Pattern 1: Multiple articles with various connectors (improved)\n",
    "    r'\\b(?:art[√≠i]culos?|art\\.?)\\s*\\d+(?:\\s*[¬∞¬∫])?(?:\\s*bis|ter|qu[a√°]ter)?(?:\\s*(?:y|e|al|,|;)\\s*\\d+(?:\\s*[¬∞¬∫])?(?:\\s*bis|ter|qu[a√°]ter)?)*',\n",
    "    \n",
    "    # Pattern 2: Ranges with \"del X al Y\" or \"X al Y\"\n",
    "    r'\\b(?:art[√≠i]culos?|art\\.?)\\s*(?:del\\s*)?\\d+(?:\\s*[¬∞¬∫])?(?:\\s*bis|ter|qu[a√°]ter)?\\s*al\\s*\\d+(?:\\s*[¬∞¬∫])?(?:\\s*bis|ter|qu[a√°]ter)?',\n",
    "    \n",
    "    # Pattern 3: Comma-separated lists (1, 2, 3, 4 y 5)\n",
    "    r'\\b(?:art[√≠i]culos?|art\\.?)\\s*\\d+(?:\\s*[¬∞¬∫])?(?:\\s*bis|ter|qu[a√°]ter)?(?:\\s*,\\s*\\d+(?:\\s*[¬∞¬∫])?(?:\\s*bis|ter|qu[a√°]ter)?)*(?:\\s*(?:y|e)\\s*\\d+(?:\\s*[¬∞¬∫])?(?:\\s*bis|ter|qu[a√°]ter)?)?',\n",
    "    \n",
    "    # Pattern 4: Individual articles (backup)\n",
    "    r'\\b(?:art[√≠i]culos?|art\\.?)\\s*\\d+(?:\\s*[¬∞¬∫])?(?:\\s*bis|ter|qu[a√°]ter)?'\n",
    "]\n",
    "\n",
    "print(\"Testing improved patterns:\")\n",
    "test_cases_all = [\n",
    "    \"art√≠culos 22 y 23 de la Ley\",\n",
    "    \"seg√∫n el art√≠culo 15 bis y 16 ter\",\n",
    "    \"art√≠culos 1¬∞, 2¬∞, y 3¬∞ del reglamento\", \n",
    "    \"art√≠culos del 50 al 75 de la ley\",\n",
    "    \"art. 123, 124 y 125 establecen\",\n",
    "    \"art√≠culos 1, 2, 3, 4 y 5 determinan\",\n",
    "    \"art√≠culo 25 qu√°ter de la ley\"\n",
    "]\n",
    "\n",
    "for case in test_cases_all:\n",
    "    print(f\"\\nText: {case}\")\n",
    "    for i, pattern in enumerate(improved_patterns, 1):\n",
    "        matches = re.findall(pattern, case, re.IGNORECASE)\n",
    "        if matches:\n",
    "            print(f\"  Improved Pattern {i} ‚úÖ: {matches[0]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üîç RECOMMENDATIONS:\")\n",
    "print(\"1. ‚úÖ Your current patterns should work for 'art√≠culos 22 y 23'\")\n",
    "print(\"2. üí° Consider adding comma-separated pattern for complex lists\")\n",
    "print(\"3. üîß Add 'e' as alternative to 'y' (Spanish grammar)\")\n",
    "print(\"4. üìù Consider semicolon (;) as separator in formal texts\")\n",
    "print(\"5. üéØ Pattern priority: Most specific ‚Üí Most general\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8197c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mentions_df = mentions_df[['entity_id','source_row_id','original_text','entity_text', 'entity_label','pattern_group']]\n",
    "mentions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ee79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save entity recognition results with IDs\n",
    "\n",
    "mentions_output = '/Users/alexa/Projects/cdmx_kg/data/mentions_extracted_complete.csv'\n",
    "mentions_df.to_csv(mentions_output, index=False, encoding='utf-8-sig')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdmx_kg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
